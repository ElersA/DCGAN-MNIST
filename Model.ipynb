{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why DCGAN instead of GAN?\n",
    "\n",
    "Generative Adversarial Networks (GANs) use two networks to generate data (generator) and classify if it is real or generated (discriminator). These two networks continuously tries to improve their abilities and after training one can supply some noise to the generator and it will generate some output, e.g. a cat if it has been trained on cat pictures.  \n",
    "\n",
    "Problems with GANs are that they are hard to train, the model can collapse, slight changes in variables/architecture can destabilize the model, i.e. training GANs is somewhat of an art according to some. Deep Convolutional GANs (DCGANs) solves/mitigates these problems.  \n",
    "\n",
    "### Main differences between DCGANs and GANs\n",
    "Making three changes to GANs allows them to become more stable and produce better results.  \n",
    "\n",
    "The first change is to replace pooling functions with convolution layers.  \n",
    "The second change is to remove fully connected layers on top of convolutional layers.  \n",
    "The third change to use batch normalization (although with some caveats...)\n",
    "\n",
    "![title](./guidelines.png)\n",
    "\n",
    "Source: DCGAN-paper by Radford, Metz & Chintala  \n",
    "https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "## General Architecture of DCGANs\n",
    "The general architecture of a DCGAN is very similar to a GAN, both can even contain deep convolutional layers despite the names. The architecture consists of a generator which generates an image out of some initial noise and a discriminator which classifies real and fake images. The picture below gives an overview of a GAN/DCGAN.\n",
    "\n",
    "![title](./GAN-architecture.png)\n",
    "\n",
    "Source: https://towardsdatascience.com/deep-generative-models-25ab2821afd3 \n",
    "\n",
    "### DCGAN loss function\n",
    "Our DCGAN will use two cost functions, one for the generator and one for the discriminator. One can choose among several different cost functions for the the generator, we chose a heuristically motivated cost function which ensures that the \"losing\" network's gradient is strong. \n",
    "\n",
    "- Ex~pdata = Average value that x takes when it is drawn from its distribution\n",
    "- z = Input distribution to generator \n",
    "- G(z) = Output from the generator given z\n",
    "- D(G(z)) = The discriminators classification of G(z), i.e. real or false\n",
    "\n",
    "**Generator loss function**     \n",
    "![title](./generatorCost.png)\n",
    "\n",
    "\n",
    "**Discriminator loss function**\n",
    "![title](./discriminatorCost.png)\n",
    "\n",
    "Source: NIPS 2016 Tutorial: Generative Adversarial Networks  \n",
    "https://arxiv.org/pdf/1701.00160.pdf\n",
    "\n",
    "### Initial hyperparameters  \n",
    "The DCGAN-paper presents some hyperparameters which worked well\n",
    "\n",
    "- Mini-batch size: 128\n",
    "- Weights initialization: Zero-centered normal distribution with standard deviation 0.02\n",
    "- LeakyReLU leak: 0.2\n",
    "- Optimizer: Adam with learning rate 0.0002 and Beta1 0.5 (default, 0.9, caused oscillations). Beta1 is momentum decay  \n",
    "\n",
    "The DCGAN-paper's authors also mention that removing bias and scaling parameters from batch norm gave better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# to make this notebook's output stable across runs (from lab2)\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructs DCCGAN with tf.Keras\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set parameters\n",
    "        self.rows = 28\n",
    "        self.columns = 28\n",
    "        self.channels = 1\n",
    "        self.shape = (self.rows, self.columns, self.channels) # Image shape \n",
    "        self.batch_size = 128\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        # Build the models\n",
    "        self.generator = self._buildGenerator()\n",
    "        self.discriminator = self._buildDiscriminator()\n",
    "        \n",
    "        # Compile the models\n",
    "        self.generator.compile()\n",
    "        self.discriminator.compile()\n",
    "        \n",
    "        # Train the models\n",
    "        \n",
    "        \n",
    "    # Currently following this: https://julianzaidi.wordpress.com/2017/04/24/deep-convolution-gan-dcgan-architecture-and-training/\n",
    "    def _buildGenerator(self):\n",
    "        \"\"\"\n",
    "        Constructs the generator part of the DCGAN\n",
    "        \"\"\"\n",
    "        ##########\n",
    "        # Layers #\n",
    "        ##########\n",
    "        # 1. Input\n",
    "        # 2. Reshape layer\n",
    "        # 3. Transposed conv layer\n",
    "        # 4. Transposed conv layer\n",
    "        # 5. Transposed conv layer\n",
    "        # 6. Transposed conv layer\n",
    "        # 7. Transposed conv layer\n",
    "        \n",
    "        #model = tf.keras.Input() # Sequential or Functional API?\n",
    "        # In the blog post they use a reshape, is that neccessary? Investigate\n",
    "        noise = np.random.uniform(low=-1.0, high=1.0, size=(self.batch_size, 100, 1, 1))\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # Read the link below to understand output shapes of Conv2DTranspose\n",
    "        # https://stackoverflow.com/questions/50683039/conv2d-transpose-output-shape-using-formula\n",
    "        # Output shape: (batch, new_rows, new_cols, filters)\n",
    "        model.add(layers.Conv2DTranspose(input_shape=(self.batch_size, 100, 1, 1), filters=512, \n",
    "                                         kernel_size=(4,4), strides=(1,1), padding=\"valid\",\n",
    "                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "        model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "        model.add(layers.ReLU())\n",
    "        \n",
    "        model.add(layers.Conv2DTranspose(filters=256, kernel_size=(4,4), strides=(2,2), padding=\"valid\",\n",
    "                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "        model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "        model.add(layers.ReLU())\n",
    "        \n",
    "        model.add(layers.Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding=\"valid\",\n",
    "                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "        model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "        model.add(layers.ReLU())\n",
    "        \n",
    "        model.add(layers.Conv2DTranspose(filters=64, kernel_size=(4,4), strides=(2,2), padding=\"valid\",\n",
    "                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "        model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "        model.add(layers.ReLU())\n",
    "    \n",
    "        model.add(layers.Conv2DTranspose(filters=1, kernel_size=(4,4), strides=(2,2), padding=\"valid\",\n",
    "                                         kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02),\n",
    "                                         activation='tanh'))\n",
    "    \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _buildDiscriminator(self):\n",
    "        \"\"\"\n",
    "        Constructs the discriminator part of the DCGAN\n",
    "        \"\"\"\n",
    "        ##########\n",
    "        # Layers #\n",
    "        ##########\n",
    "        # 1. Input\n",
    "        # 2. Conv layer\n",
    "        # 3. Conv layer\n",
    "        # 4. Dense layer\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # Input is batchx28x28x1\n",
    "        model.add(layers.Conv2D(input_shape=(None, 28, 28, 1), filters= ,\n",
    "                                kernel_size=(), strides=(), padding=\"valid\",\n",
    "                                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "        model.add(layers.LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        # Input is batchx14x14x???\n",
    "        model.add(layers.Conv2D(filters= , kernel_size=(), \n",
    "                                strides=(), padding=\"valid\",\n",
    "                                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "        model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "        model.add(layers.LeakyReLU(alpha=0.2))\n",
    "        \n",
    "        # Input is batchx7x7x???\n",
    "        model.add(layers.Flatten()) # Output is batchx7*7*???\n",
    "        model.add(layers.Dense(kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02),\n",
    "                               activation=tf.nn.sigmoid))\n",
    "    \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def trainModel(self):\n",
    "        \"\"\"\n",
    "        Trains the generator and discriminator\n",
    "        \"\"\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.13897881]]\n",
      "\n",
      "  [[ 0.11966697]]]\n",
      "\n",
      "\n",
      " [[[-0.47545968]]\n",
      "\n",
      "  [[ 0.2212227 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.19881932]]\n",
      "\n",
      "  [[-0.03660763]]]]\n"
     ]
    }
   ],
   "source": [
    "#noise = np.random.normal(loc=0 , scale=0.2 , size=(3, 2, 1, 1))\n",
    "#print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 3, 1)\n",
      "(2, 3, 1, 1)\n",
      "[[[[-0.15162636]]\n",
      "\n",
      "  [[-0.31837529]]\n",
      "\n",
      "  [[-0.26284121]]]\n",
      "\n",
      "\n",
      " [[[-0.37285482]]\n",
      "\n",
      "  [[-0.00284007]]\n",
      "\n",
      "  [[ 0.22228344]]]]\n",
      "\n",
      "[[[[-0.29609413]]\n",
      "\n",
      "  [[-0.24723667]]\n",
      "\n",
      "  [[ 0.30993767]]]\n",
      "\n",
      "\n",
      " [[[-0.98739054]]\n",
      "\n",
      "  [[-0.47790569]]\n",
      "\n",
      "  [[-0.94762318]]]]\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# This cell shows that we don't need to reshape our initial noise\n",
    "# We can just specify all dims when creating the noise\n",
    "#########################\n",
    "noise = np.random.uniform(low=-1.0, high=1.0, size=(2, 3))\n",
    "print(noise.shape)\n",
    "y = np.expand_dims(noise, axis=2)\n",
    "print(y.shape)\n",
    "z = np.expand_dims(y, axis=3)\n",
    "print(z.shape)\n",
    "print(z)\n",
    "print()\n",
    "print(np.random.uniform(low=-1.0, high=1.0, size=(2, 3,1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4, 4, 128)         256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 11, 11, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 64)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         4097      \n",
      "=================================================================\n",
      "Total params: 414,273\n",
      "Trainable params: 413,889\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try different values and see the output dimensions of each layer\n",
    "# Experiment and find suitable values\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "noise = np.random.uniform(low=-1.0, high=1.0, size=(batch_size, 1, 1, 100))\n",
    "\n",
    "model.add(layers.Conv2DTranspose(input_shape=(1, 1, 100), filters=128, kernel_size=(4,4), strides=(1,1), padding=\"valid\",\n",
    "                                 kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Conv2DTranspose(filters=64, kernel_size=(5,5), strides=(2,2), padding=\"valid\",\n",
    "                                 kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
    "model.add(layers.BatchNormalization(scale=False, center=False))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Conv2DTranspose(filters=1, kernel_size=(8,8), strides=(2,2), padding=\"valid\",\n",
    "                                 kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02),\n",
    "                                 activation='tanh'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
